{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\nNASA Readies Perseverance Mars Rover's Earthly Twin \n\n\n\nDid you know NASA's next Mars rover has a nearly identical sibling on Earth for testing? Even better, it's about to roll for the first time through a replica Martian landscape.\n\n"
    }
   ],
   "source": [
    "# Pull News Title and Paragraph Text\n",
    "\n",
    "# Base news page\n",
    "News_URL = \"https://mars.nasa.gov/news/\"\n",
    "# Pulls URL and parses to HTML using BeautifulSoup\n",
    "News_Response = requests.get(News_URL)\n",
    "News_Soup = BeautifulSoup(News_Response.text, 'html.parser')\n",
    "# Pulls the text of the title, and paragraph based on their parent div classes\n",
    "news_title = News_Soup.find(\"div\", class_=\"content_title\").text\n",
    "news_p = News_Soup.find(\"div\", class_=\"rollover_description_inner\").text\n",
    "# Test Output\n",
    "print(news_title)\n",
    "print(news_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA19334_hires.jpg\n"
    }
   ],
   "source": [
    "# Pull largesize image from featured page\n",
    "\n",
    "# Base image page\n",
    "Small_Image_URL = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "# Pulls URL and parses to HTML using BeautifulSoup\n",
    "Small_Image_Response = requests.get(Small_Image_URL)\n",
    "Small_Image_Soup = BeautifulSoup(Small_Image_Response.text, 'html.parser')\n",
    "# Pulls the target from the \"more info\" button to get a new URL to reference the full size image\n",
    "Details_Page_URL = Small_Image_Soup.find(\"a\", class_=\"button fancybox\")[\"data-link\"]\n",
    "# Combine base with full size image URLs\n",
    "Full_Image_URL = \"https://www.jpl.nasa.gov\" + Details_Page_URL\n",
    "# Pulls NEW URL and parses to HTML using BeautifulSoup\n",
    "Full_Image_Response = requests.get(Full_Image_URL)\n",
    "Full_Image_Soup = BeautifulSoup(Full_Image_Response.text, 'html.parser')\n",
    "# Pulls tag contating full size image\n",
    "Full_Image_URL = Full_Image_Soup.find('figure', class_=\"lede\")\n",
    "# Combines base with final target URLs\n",
    "featured_image_url = \"https://www.jpl.nasa.gov\" + Full_Image_URL.a['href']\n",
    "# Test Output\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                   Mars                        Metrics\n0  Equatorial Diameter:                       6,792 km\n1       Polar Diameter:                       6,752 km\n2                 Mass:  6.39 × 10^23 kg (0.11 Earths)\n3                Moons:            2 (Phobos & Deimos)\n4       Orbit Distance:       227,943,824 km (1.38 AU)\n5         Orbit Period:           687 days (1.9 years)\n6  Surface Temperature:                   -87 to -5 °C\n7         First Record:              2nd millennium BC\n8          Recorded By:           Egyptian astronomers",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mars</th>\n      <th>Metrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Equatorial Diameter:</td>\n      <td>6,792 km</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Polar Diameter:</td>\n      <td>6,752 km</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Mass:</td>\n      <td>6.39 × 10^23 kg (0.11 Earths)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Moons:</td>\n      <td>2 (Phobos &amp; Deimos)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Orbit Distance:</td>\n      <td>227,943,824 km (1.38 AU)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Orbit Period:</td>\n      <td>687 days (1.9 years)</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Surface Temperature:</td>\n      <td>-87 to -5 °C</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>First Record:</td>\n      <td>2nd millennium BC</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Recorded By:</td>\n      <td>Egyptian astronomers</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Pull Mars details table \n",
    "\n",
    "# Base table page\n",
    "Stats_URL = \"https://space-facts.com/mars/\"\n",
    "# Use built in Pandas function to read the webpage\n",
    "Stats_Table = pd.read_html(Stats_URL)\n",
    "# Finds first tatble and assigns it to dataframe\n",
    "Stats_Table_df = Stats_Table[0]\n",
    "# Clean format of DataFrame prior to HTML output\n",
    "Stats_Table_df.columns = [\"Mars\",\"Metrics\"]\n",
    "Stats_Table_df.reset_index(drop=True, inplace=True)\n",
    "# Output table in HTML format to be used in landing page\n",
    "Stats_html = Stats_Table_df.to_html(index=False)\n",
    "# Test Output\n",
    "Stats_Table_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                  title  \\\n0          Cerberus Hemisphere Enhanced   \n1      Schiaparelli Hemisphere Enhanced   \n2      Syrtis Major Hemisphere Enhanced   \n3  Valles Marineris Hemisphere Enhanced   \n\n                                             img_url  \n0  https://astrogeology.usgs.gov/cache/images/f5e...  \n1  https://astrogeology.usgs.gov/cache/images/377...  \n2  https://astrogeology.usgs.gov/cache/images/555...  \n3  https://astrogeology.usgs.gov/cache/images/b3c...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>img_url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cerberus Hemisphere Enhanced</td>\n      <td>https://astrogeology.usgs.gov/cache/images/f5e...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Schiaparelli Hemisphere Enhanced</td>\n      <td>https://astrogeology.usgs.gov/cache/images/377...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Syrtis Major Hemisphere Enhanced</td>\n      <td>https://astrogeology.usgs.gov/cache/images/555...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Valles Marineris Hemisphere Enhanced</td>\n      <td>https://astrogeology.usgs.gov/cache/images/b3c...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# THIS KERNEL TAKES A WHILE TO FULLY PROCESS, PLEASE BE PATIENT\n",
    "# Pull all 4 enhanced image titles and URLs - \n",
    "\n",
    "\n",
    "# Base hemispheres page\n",
    "Hemisphere_Base_URL = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "# Pulls URL and parses to HTML using BeautifulSoup\n",
    "Hemisphere_Base_Response = requests.get(Hemisphere_Base_URL)\n",
    "Hemisphere_Base_Soup = BeautifulSoup(Hemisphere_Base_Response.text, 'html.parser')\n",
    "# Finds all 'item' class div tags\n",
    "Hemisphere_List = Hemisphere_Base_Soup.find_all('div', class_=\"item\")\n",
    "# Establish list variables to append to\n",
    "titles = []\n",
    "raw_img_urls = []\n",
    "full_img_urls = []\n",
    "# First loop - gets titles and URLs for enhanced photo TARGET LINKS\n",
    "for x in Hemisphere_List:\n",
    "    # Add currrently looped title to titles list\n",
    "    titles.append(x.div.text)\n",
    "    # Combine base with full size image URLs and add currrently looped URL to raw image list\n",
    "    raw_img_urls.append(\"https://astrogeology.usgs.gov\" + x.a[\"href\"])\n",
    "# Second loop - for each TARGET LINK, get the full size image URL from each of those pages\n",
    "for x in raw_img_urls:\n",
    "    # Pulls currently looped URL and parses to HTML using BeautifulSoup\n",
    "    Hemisphere_response = requests.get(x)\n",
    "    Hemisphere_Soup = BeautifulSoup(Hemisphere_response.text, 'html.parser')\n",
    "    # Pulls full size image URL from TARGET LINK\n",
    "    Hemisphere_url = Hemisphere_Soup.find(\"img\", class_=\"wide-image\")[\"src\"]\n",
    "    # Combine base URL with full image URL and add currrently looped URL to full size image list\n",
    "    full_img_urls.append(\"https://astrogeology.usgs.gov\" + Hemisphere_url)\n",
    "# Create dataframe and assign titles and full size image URLs as columns\n",
    "Hemisphere_df = pd.DataFrame()\n",
    "Hemisphere_df[\"title\"] = titles\n",
    "Hemisphere_df[\"img_url\"] = full_img_urls\n",
    "# Test Output\n",
    "Hemisphere_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[{'title': 'Cerberus Hemisphere Enhanced',\n  'img_url': 'https://astrogeology.usgs.gov/cache/images/f5e372a36edfa389625da6d0cc25d905_cerberus_enhanced.tif_full.jpg',\n  '_id': ObjectId('5f73c07a638abb2900708c3c')},\n {'title': 'Schiaparelli Hemisphere Enhanced',\n  'img_url': 'https://astrogeology.usgs.gov/cache/images/3778f7b43bbbc89d6e3cfabb3613ba93_schiaparelli_enhanced.tif_full.jpg',\n  '_id': ObjectId('5f73c07a638abb2900708c3d')},\n {'title': 'Syrtis Major Hemisphere Enhanced',\n  'img_url': 'https://astrogeology.usgs.gov/cache/images/555e6403a6ddd7ba16ddb0e471cadcf7_syrtis_major_enhanced.tif_full.jpg',\n  '_id': ObjectId('5f73c07a638abb2900708c3e')},\n {'title': 'Valles Marineris Hemisphere Enhanced',\n  'img_url': 'https://astrogeology.usgs.gov/cache/images/b3c7c6c9138f57b4756be9b9c43e3a48_valles_marineris_enhanced.tif_full.jpg',\n  '_id': ObjectId('5f73c07a638abb2900708c3f')},\n {'title': \"\\n\\nNASA Readies Perseverance Mars Rover's Earthly Twin \\n\\n\",\n  'img_url': \"\\nDid you know NASA's next Mars rover has a nearly identical sibling on Earth for testing? Even better, it's about to roll for the first time through a replica Martian landscape.\\n\",\n  '_id': ObjectId('5f73c07a638abb2900708c40')},\n {'title': 'Featured Image',\n  'img_url': 'https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA19334_hires.jpg',\n  '_id': ObjectId('5f73c07a638abb2900708c41')},\n {'title': 'Stats Table',\n  'img_url': '<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th>Mars</th>\\n      <th>Metrics</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <td>Equatorial Diameter:</td>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <td>Polar Diameter:</td>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <td>Mass:</td>\\n      <td>6.39 × 10^23 kg (0.11 Earths)</td>\\n    </tr>\\n    <tr>\\n      <td>Moons:</td>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Distance:</td>\\n      <td>227,943,824 km (1.38 AU)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Period:</td>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <td>Surface Temperature:</td>\\n      <td>-87 to -5 °C</td>\\n    </tr>\\n    <tr>\\n      <td>First Record:</td>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <td>Recorded By:</td>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>',\n  '_id': ObjectId('5f73c07a638abb2900708c42')}]"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Combine data into one dictionary and output to MondoDB\n",
    "Mongo_df = Hemisphere_df.append({\"title\":news_title, \"img_url\":news_p}, ignore_index=True)\n",
    "Mongo_df = Mongo_df.append({\"title\":\"Featured Image\",\"img_url\":featured_image_url}, ignore_index=True)\n",
    "Mongo_df = Mongo_df.append({\"title\":\"Stats Table\",\"img_url\": Stats_html}, ignore_index=True)\n",
    "Mongo_dict = Mongo_df.to_dict(\"records\")\n",
    "\n",
    "# Setup connection to mongodb\n",
    "conn = \"mongodb://localhost:27017\"\n",
    "client = pymongo.MongoClient(conn)\n",
    "# Clears existing database for fresh start\n",
    "client.mars_db.web_links.drop()\n",
    "# Add all items to be passed to index.html into MongoDB\n",
    "client.mars_db.web_links.insert(Mongo_dict)\n",
    "# Test Output\n",
    "Mongo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create single function to scrape all the data, export it to mongodb and html file\n",
    "def scrapeData():\n",
    "    # Import Dependencies\n",
    "    from bs4 import BeautifulSoup\n",
    "    import pandas as pd\n",
    "    import requests\n",
    "    import pymongo\n",
    "\n",
    "    # Base news page\n",
    "    News_URL = \"https://mars.nasa.gov/news/\"\n",
    "    # Pulls URL and parses to HTML using BeautifulSoup\n",
    "    News_Response = requests.get(News_URL)\n",
    "    News_Soup = BeautifulSoup(News_Response.text, 'html.parser')\n",
    "    # Pulls the text of the title, and paragraph based on their parent div classes\n",
    "    news_title = News_Soup.find(\"div\", class_=\"content_title\").text\n",
    "    news_p = News_Soup.find(\"div\", class_=\"rollover_description_inner\").text\n",
    "\n",
    "    # Base image page\n",
    "    Small_Image_URL = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    # Pulls URL and parses to HTML using BeautifulSoup\n",
    "    Small_Image_Response = requests.get(Small_Image_URL)\n",
    "    Small_Image_Soup = BeautifulSoup(Small_Image_Response.text, 'html.parser')\n",
    "    # Pulls the target from the \"more info\" button to get a new URL to reference the full size image\n",
    "    Details_Page_URL = Small_Image_Soup.find(\"a\", class_=\"button fancybox\")[\"data-link\"]\n",
    "    # Combine base with full size image URLs\n",
    "    Full_Image_URL = \"https://www.jpl.nasa.gov\" + Details_Page_URL\n",
    "    # Pulls NEW URL and parses to HTML using BeautifulSoup\n",
    "    Full_Image_Response = requests.get(Full_Image_URL)\n",
    "    Full_Image_Soup = BeautifulSoup(Full_Image_Response.text, 'html.parser')\n",
    "    # Pulls tag contating full size image\n",
    "    Full_Image_URL = Full_Image_Soup.find('figure', class_=\"lede\")\n",
    "    # Combines base with final target URLs\n",
    "    featured_image_url = \"https://www.jpl.nasa.gov\" + Full_Image_URL.a['href']\n",
    "\n",
    "    # Base table page\n",
    "    Stats_URL = \"https://space-facts.com/mars/\"\n",
    "    # Use built in Pandas function to read the webpage\n",
    "    Stats_Table = pd.read_html(Stats_URL)\n",
    "    # Finds first tatble and assigns it to dataframe\n",
    "    Stats_Table_df = Stats_Table[0]\n",
    "    # Clean format of DataFrame prior to HTML output\n",
    "    Stats_Table_df.columns = [\"Mars\",\"Metrics\"]\n",
    "    Stats_Table_df.reset_index(drop=True, inplace=True)\n",
    "    # Output table in HTML format to be used in landing page\n",
    "    Stats_html = Stats_Table_df.to_html(index=False)\n",
    "\n",
    "    # Base hemispheres page\n",
    "    Hemisphere_Base_URL = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "    # Pulls URL and parses to HTML using BeautifulSoup\n",
    "    Hemisphere_Base_Response = requests.get(Hemisphere_Base_URL)\n",
    "    Hemisphere_Base_Soup = BeautifulSoup(Hemisphere_Base_Response.text, 'html.parser')\n",
    "    # Finds all 'item' class div tags\n",
    "    Hemisphere_List = Hemisphere_Base_Soup.find_all('div', class_=\"item\")\n",
    "    # Establish list variables to append to\n",
    "    titles = []\n",
    "    raw_img_urls = []\n",
    "    full_img_urls = []\n",
    "    # First loop - gets titles and URLs for enhanced photo TARGET LINKS\n",
    "    for x in Hemisphere_List:\n",
    "        # Add currrently looped title to titles list\n",
    "        titles.append(x.div.text)\n",
    "        # Combine base with full size image URLs and add currrently looped URL to raw image list\n",
    "        raw_img_urls.append(\"https://astrogeology.usgs.gov\" + x.a[\"href\"])\n",
    "    # Second loop - for each TARGET LINK, get the full size image URL from each of those pages\n",
    "    for x in raw_img_urls:\n",
    "        # Pulls currently looped URL and parses to HTML using BeautifulSoup\n",
    "        Hemisphere_response = requests.get(x)\n",
    "        Hemisphere_Soup = BeautifulSoup(Hemisphere_response.text, 'html.parser')\n",
    "        # Pulls full size image URL from TARGET LINK\n",
    "        Hemisphere_url = Hemisphere_Soup.find(\"img\", class_=\"wide-image\")[\"src\"]\n",
    "        # Combine base URL with full image URL and add currrently looped URL to full size image list\n",
    "        full_img_urls.append(\"https://astrogeology.usgs.gov\" + Hemisphere_url)\n",
    "    # Create dataframe and assign titles and full size image URLs as columns\n",
    "    Hemisphere_df = pd.DataFrame()\n",
    "    Hemisphere_df[\"title\"] = titles\n",
    "    Hemisphere_df[\"img_url\"] = full_img_urls\n",
    "\n",
    "    # Combine data into one dictionary and output to MondoDB\n",
    "    Mongo_df = Hemisphere_df.append({\"title\":news_title, \"img_url\":news_p}, ignore_index=True)\n",
    "    Mongo_df = Mongo_df.append({\"title\":\"Featured Image\",\"img_url\":featured_image_url}, ignore_index=True)\n",
    "    Mongo_df = Mongo_df.append({\"title\":\"Stats Table\",\"img_url\": Stats_html}, ignore_index=True)\n",
    "    Mongo_dict = Mongo_df.to_dict(\"records\")\n",
    "\n",
    "    # Setup connection to mongodb\n",
    "    conn = \"mongodb://localhost:27017\"\n",
    "    client = pymongo.MongoClient(conn)\n",
    "    # Clears existing database for fresh start\n",
    "    client.mars_db.web_links.drop()\n",
    "    # Add all items to be passed to index.html into MongoDB\n",
    "    client.mars_db.web_links.insert(Mongo_dict)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Output\n",
    "scrapeData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}